{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import math\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set locations for working files\n",
    "if len(sys.argv) != 3:\n",
    "    print(\"Usage: python3 process-sim.py <automation_dir> <attpcroot_dir>\")\n",
    "    print('Assuming testing directories')\n",
    "    automation_dir = '/mnt/analysis/e17023/Adam/GADGET/.sims/0/'\n",
    "    attpcroot_dir = automation_dir + 'ATTPCROOTv2/'\n",
    "else:\n",
    "    # Automation directory\n",
    "    automation_dir = sys.argv[1]\n",
    "    \n",
    "    # ATTPCROOTv2 directory\n",
    "    attpcroot_dir = sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_file(file_type, indicator_directory=automation_dir):\n",
    "    # remove old indicator file(s)\n",
    "    for file in os.listdir(indicator_directory):\n",
    "        if file.endswith('.tmp'):\n",
    "            os.remove(indicator_directory + file)\n",
    "    \n",
    "    with open(indicator_directory + file_type + '.tmp', 'w') as f:\n",
    "        f.write('1')\n",
    "    if file_type == 'STOP':\n",
    "        print('STOPPING')\n",
    "        sys.exit()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.read_csv(automation_dir + 'param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Calibration\n",
    "def kev_to_channel(event_energy, energy_resolution=4.2):\n",
    "    energy_uncertainty = energy_resolution * math.sqrt(event_energy) / 1000\n",
    "    event_energy = (event_energy / 1000) # convert to MeV\n",
    "    event_energy = np.random.normal(event_energy, energy_uncertainty)\n",
    "    \n",
    "    calib_point_1 = (0.806, 156745) ; calib_point_2 = (1.679, 320842)\n",
    "    energy_1, channel_1 = calib_point_1 ;  energy_2, channel_2 = calib_point_2\n",
    "    slope = (channel_2 - channel_1) / (energy_2 - energy_1)\n",
    "    intercept = channel_1 - slope * energy_1\n",
    "    target_channel = (event_energy * slope) + intercept\n",
    "    return target_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sim_to_raw_h5(h5_file_name, event_energy, energy_resolution):\n",
    "    print('Converting simulation h5 files to raw h5 format...')\n",
    "    \n",
    "    with open(f'{automation_dir}../../.input/padxy.txt') as padxy_lookup_txt: # TODO: non-hardcoded path\n",
    "        padxy_lookup = padxy_lookup_txt.readlines()\n",
    "    padxy_lookup = np.array([tuple(map(float, line.strip().split(','))) for line in padxy_lookup])\n",
    "    with open(f'{automation_dir}../../.input/flatlookup4cobos.csv') as flatlookup4cobos_csv:\n",
    "        flatlookup4cobos = flatlookup4cobos_csv.readlines()\n",
    "    flat_padplane_lookup = {}\n",
    "    for i, line in enumerate(flatlookup4cobos):\n",
    "        flat_padplane_lookup[i] = tuple(map(int, line.strip().split(',')))\n",
    "\n",
    "    old_format_h5 = h5py.File(f\"{h5_file_name}\", 'r')\n",
    "    new_format_h5 = h5py.File(f\"{h5_file_name.replace('.h5', '_new.h5')}\", 'w')\n",
    "    new_format_h5.create_group('get')\n",
    "    new_format_h5.create_group('meta')\n",
    "    new_format_h5.create_group('clouds')\n",
    "    \n",
    "    #meta/meta\n",
    "    new_format_h5.create_dataset(\"meta/meta\", data=[np.inf, np.inf, -1, -1], dtype='float64') # N0, T0, N1, T1\n",
    "    event_keys = [key for key in old_format_h5.keys() if \"Event_[\" in str(key)]\n",
    "    \n",
    "    for event in event_keys:\n",
    "        event_number = int(event.split('[')[1].split(']')[0])\n",
    "        \n",
    "        # get/evt#_header\n",
    "        sim_creation_time = 0 #float(h5_file_name.replace('.h5', '').split('/')[-1])\n",
    "        event_data = [event_number, sim_creation_time, event_number, 0]\n",
    "        new_format_h5.create_dataset(f\"get/evt{event_number}_header\", data=event_data, dtype='float64')\n",
    "        \n",
    "        # unique pad coordinates\n",
    "        Old_HitArray = old_format_h5[event]['HitArray']\n",
    "        pads_xy = np.column_stack((Old_HitArray['x'], Old_HitArray['y']))\n",
    "        pads_xy = np.unique(pads_xy, axis=0)\n",
    "        \n",
    "        # get/evt#data and clouds/evt#_cloud\n",
    "        raw_event_data = np.zeros((len(pads_xy), 517), dtype='int16')\n",
    "        pca_event_data = np.zeros((len(pads_xy), 5), dtype='float64')\n",
    "        for pad_index, pad in enumerate(pads_xy):        \n",
    "            \n",
    "            # locate the nearest pad based on the lookup table\n",
    "            pad_number = ((padxy_lookup - pad)**2).sum(axis=1).argmin()\n",
    "            raw_event_data[pad_index, :5] = flat_padplane_lookup[pad_number] # Cobo, ASAD, AGET, channel, pad\n",
    "            \n",
    "            pca_event_data[pad_index, 0:2] = pad # x, y\n",
    "            pca_event_data[pad_index, 4] = pad_number\n",
    "            max_ze = (0,0)\n",
    "            \n",
    "            pad_hits = Old_HitArray[(Old_HitArray['x'] == pad[0]) & (Old_HitArray['y'] == pad[1])]\n",
    "            for hit in pad_hits:\n",
    "                raw_event_data[pad_index, hit['t']+5] += hit['A'] #TODO check if T or Z is the correct value to use\n",
    "                pca_event_data[pad_index, 3] += hit['A']\n",
    "                \n",
    "                if hit['A'] > max_ze[1]:\n",
    "                    pca_event_data[pad_index, 2] = hit['z']\n",
    "                    max_ze = (hit['z'], hit['A'])\n",
    "        \n",
    "        # Energy Calibration - disabled for now\n",
    "        '''\n",
    "        simulated_channel = np.sum(pca_event_data[:, 3])\n",
    "        target_channel = kev_to_channel(event_energy, energy_resolution)\n",
    "        while target_channel < 0: # ensure that the target channel is positive\n",
    "            target_channel = kev_to_channel(event_energy, energy_resolution)\n",
    "            #TODO: potential infinite loop if the energy is too low \n",
    "        raw_event_data[:, 5:] = raw_event_data[:, 5:] * (target_channel / simulated_channel)\n",
    "        pca_event_data[:, 3] = pca_event_data[:, 3] * (target_channel / simulated_channel)\n",
    "        '''\n",
    "        \n",
    "        # save the data\n",
    "        new_format_h5.create_dataset(f\"get/evt{event_number}_data\", data=raw_event_data, dtype='int16')\n",
    "        new_format_h5.create_dataset(f\"clouds/evt{event_number}_cloud\", data=pca_event_data, dtype='float64')\n",
    "        \n",
    "        # update meta/meta\n",
    "        new_format_h5['meta/meta'][0] = min(new_format_h5['meta/meta'][0], event_number)\n",
    "        new_format_h5['meta/meta'][1] = min(new_format_h5['meta/meta'][1], sim_creation_time)\n",
    "        new_format_h5['meta/meta'][2] = max(new_format_h5['meta/meta'][2], event_number)\n",
    "        new_format_h5['meta/meta'][3] = max(new_format_h5['meta/meta'][3], sim_creation_time)\n",
    "        \n",
    "        #TODO: COBO/ASAD Metadata files\n",
    "        #TODO: Simulation parameters stored directly inside h5 file\n",
    "        \n",
    "    # close the files\n",
    "    old_format_h5.close()\n",
    "    new_format_h5.close()\n",
    "    \n",
    "    os.remove(f\"{h5_file_name}\")\n",
    "    os.rename(f\"{h5_file_name.replace('.h5', '_new.h5')}\", f\"{h5_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for and complete any active simulations\n",
    "\n",
    "# 0 = inactive\n",
    "# 1 = active\n",
    "# 2 = complete\n",
    "indicator_file('PROCESSING H5')\n",
    "\n",
    "active_sims = parameters[parameters['Status'] == 1]\n",
    "\n",
    "if len(active_sims) > 1:\n",
    "    print('More than one simulation marked as active')\n",
    "    indicator_file('STOP')\n",
    "\n",
    "# Search for output.h5 and rename\n",
    "Complete = False\n",
    "try:\n",
    "    #h5_name = f\"{automation_dir}out/{active_sims.loc[active_sims.index[0],'Sim']}.h5\"\n",
    "    h5_name = f\"{automation_dir}out/output.h5\"\n",
    "    #os.rename(f\"{automation_dir}out/output.h5\", h5_name)\n",
    "    \n",
    "    event_energy = active_sims.loc[active_sims.index[0], 'E0'] + active_sims.loc[active_sims.index[0], 'E1']\n",
    "    \n",
    "    energy_resolution = active_sims.loc[active_sims.index[0], 'EnergyResolution'] if 'EnergyResolution' in active_sims.columns else 4.2\n",
    "    \n",
    "    convert_sim_to_raw_h5(h5_name, event_energy, energy_resolution)\n",
    "    \n",
    "    # copy h5 file to the correct directory\n",
    "    os.system(f\"cp {h5_name} {automation_dir}out/hdf5/{active_sims.loc[active_sims.index[0],'Sim']}.h5\")\n",
    "    Complete = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Set Status in parameters\n",
    "if Complete:\n",
    "    parameters.loc[active_sims.index[0], 'Status'] = 2\n",
    "    if 'Time' in parameters.columns:\n",
    "        parameters.loc[active_sims.index[0], 'Time'] = time.time() - parameters.loc[active_sims.index[0], 'Time']\n",
    "else:\n",
    "    print('No output.h5 found')\n",
    "    indicator_file('STOP')\n",
    "\n",
    "# Update parameters.csv to reflect complete h5 file\n",
    "parameters.to_csv(automation_dir + 'param.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
