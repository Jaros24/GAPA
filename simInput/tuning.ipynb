{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "rseed = 0\n",
    "\n",
    "# read in the working directories and iteration number\n",
    "if len(sys.argv) == 4:\n",
    "    # set locations for working files\n",
    "    automation_dir = sys.argv[1]\n",
    "    attpcroot_dir = sys.argv[2]\n",
    "    iteration = int(sys.argv[3])\n",
    "    \n",
    "    if rseed == 0:\n",
    "        rseed = random.randint(1,1000000)\n",
    "    \n",
    "else:\n",
    "    if testing:\n",
    "        print(\"TESTING MODE\")\n",
    "        automation_dir = '/mnt/analysis/e17023/Adam/GADGET2/'\n",
    "        attpcroot_dir = '/mnt/analysis/e17023/Adam/ATTPCROOTv2/'\n",
    "        iteration = 2\n",
    "        print(f\"Using default directories and iteration {iteration}\")\n",
    "    else:\n",
    "        print(\"Usage: python tuning.py <automation_dir> <attpcroot_dir> <iteration>\")\n",
    "        raise ValueError(\"Incorrect number of arguments passed to tuning.py\")\n",
    "rseed += iteration # to ensure that the random seed is different for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_file(file_type, indicator_directory=automation_dir):\n",
    "    df = pd.DataFrame([0])\n",
    "    df.to_csv(indicator_directory + file_type + '.csv', index=False)\n",
    "    print(file_type + ' FILE CREATED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_files():\n",
    "    param_df = pd.DataFrame(columns=['Sim', 'Status', 'P0', 'E0', 'P1', 'E1', 'N', 'Seed', 'Score'])\n",
    "    tuning_log = {\n",
    "        'Parameters': { # initial values of tuning parameters, changed to best fit values after each iteration\n",
    "            'Threshold' : 100,\n",
    "            'EIonize' : 22.3,\n",
    "            'Fano' : 0.24,\n",
    "            'CoefL' : 0.000114,\n",
    "            'CoefT' : 0.00284,\n",
    "            'Gain' : 8000,\n",
    "            'GETGain' : 120,\n",
    "            'PeakingTime' : 1014,\n",
    "            'GasPressure' : 800\n",
    "        },\n",
    "        'Gradient' : {}, # measured gradient of each parameter after each iteration, used to calculate new parameter values\n",
    "        'N': 100, # number of events per simulation\n",
    "        'Seed' : 2, # seed to use for all simulations (eliminates random variation for simpler tuning, effect can be minimized with large N)\n",
    "        'TuningParticles' : ['806p', '1682p'], # Particle types to use for tuning\n",
    "        'LearningRate' : 0.1, \n",
    "        'TestJump' : 0.1, # Learning Rate * TestJump * Old Gradient = amount to change each parameter by for measuring the gradient\n",
    "        'IntParams' : ['Threshold', 'Gain', 'GETGain', 'PeakingTime'], # parameters that must be integers\n",
    "        'ZeroEnergy' : 0.001, # energy of particles that are considered to have zero energy (bad fix of a bug)\n",
    "        'Batch' : 0, # batch number\n",
    "        \n",
    "    }\n",
    "    \n",
    "     # initialize gradient to +10% of initial parameter values\n",
    "    tuning_log['Gradient'] = {param: tuning_log['Parameters'][param] * 0.1 for param in tuning_log['Parameters'].keys()}\n",
    "    \n",
    "    # batch specific parameters\n",
    "    tuning_log['VarParam'] = list(tuning_log['Parameters'].keys())[0] # currently varying parameter\n",
    "    tuning_log['VarPType'] = tuning_log['TuningParticles'][0] # currently varying particle type\n",
    "    \n",
    "    # save tuning information to json file for future iterations\n",
    "    with open(automation_dir + 'simInput/tuning_log.json', 'w') as f:\n",
    "        json.dump(tuning_log, f, indent=4)\n",
    "    \n",
    "    # add blank columns for each parameter and save to csv\n",
    "    for param in tuning_log['Parameters'].keys():\n",
    "        param_df[param] = np.nan\n",
    "    param_df.to_csv(automation_dir + 'simInput/parameters.csv', index=False)\n",
    "    \n",
    "    print('Tuning Files Initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iteration == 0:\n",
    "    initialize_files()\n",
    "else:\n",
    "    tuning_log = json.load(open(automation_dir + 'simInput/tuning_log.json'))\n",
    "    param_df = pd.read_csv(automation_dir + 'simInput/parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the parameter file and validate that all simulations have been run successfully\n",
    "param_df = pd.read_csv(automation_dir + 'simInput/parameters.csv')\n",
    "\n",
    "if 0 in param_df['Status'].values:\n",
    "    # There are still simulations queued, so exit without doing anything\n",
    "    sys.exit(0)\n",
    "elif 1 in param_df['Status'].values:\n",
    "    print(\"Error in h5 creation of one of the simulations, exiting\")\n",
    "    indicator_file('STOP')\n",
    "    sys.exit(1)\n",
    "elif 2 in param_df['Status'].values:\n",
    "    print(\"Error in image creation of one of the simulations, exiting\")\n",
    "    indicator_file('STOP')\n",
    "    sys.exit(1)\n",
    "elif 3 in param_df['Status'].values:\n",
    "    print(\"Error in GIF creation of one of the simulations, exiting\")\n",
    "    indicator_file('STOP')\n",
    "    sys.exit(1)\n",
    "\n",
    "# 4 indicates that the simulation has been run successfully\n",
    "# 5 indicates that the simulation has been run successfully and has been used for tuning already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PROCESSING FUNCTIONS\n",
    "def get_energy(image, scale=3000):\n",
    "    # extract energy bar from image\n",
    "    ebar_bounds = ((5,8),(145,17))\n",
    "    ebar = image[ebar_bounds[0][0]:ebar_bounds[1][0], ebar_bounds[0][1]:ebar_bounds[1][1], :]\n",
    "\n",
    "    ebar_slice = np.array([np.mean(ebar[i,1,:]) for i in range(ebar.shape[0])]) # 1d slice of energy bar\n",
    "    for i in range(ebar_slice.shape[0]):\n",
    "        if ebar_slice[i] != 255:\n",
    "            break\n",
    "    proportion_filled = 1 - (i-1)/ebar_slice.shape[0] # proportion of energy bar filled (0-1)\n",
    "    event_energy = (proportion_filled * scale) # scale to max energy\n",
    "    event_energy += 27.766 # offset to match data\n",
    "    return event_energy\n",
    "def get_track(image):\n",
    "    # extract padplane from image\n",
    "    padplane_bounds = ((3,40),(148,185))\n",
    "    padplane = image[padplane_bounds[0][0]:padplane_bounds[1][0], padplane_bounds[0][1]:padplane_bounds[1][1], :]\n",
    "    \n",
    "    # extract track from padplane\n",
    "    track = padplane[:,:,0].copy() # copy red channel for track\n",
    "    track[track == 255] = 0 # set white to black\n",
    "    track_bounds = np.where(track != 0) # get track bounds\n",
    "    track_bounds = ((min(track_bounds[0]), max(track_bounds[0])+1), (min(track_bounds[1]), max(track_bounds[1])+1))\n",
    "    track = track[track_bounds[0][0]:track_bounds[0][1], track_bounds[1][0]:track_bounds[1][1]] # crop track\n",
    "    track = track[::4,::4] # downsample track to remove grid effect\n",
    "    return track\n",
    "def get_trace(image):\n",
    "    trace_img = image[150:,:,0] # extract trace from image\n",
    "    trace_cumsum = np.cumsum(255-trace_img, axis=0) # cumulative sum of trace\n",
    "    trace = trace_cumsum[-1,:].astype(float) # height of trace at each pixel\n",
    "    \n",
    "    trace_diff = np.abs(np.diff(trace))\n",
    "    edges = np.arange(trace_diff.shape[0])[trace_diff > 100] # find edges of trace\n",
    "    \n",
    "    # crop trace_height to edges\n",
    "    trace = trace[edges[0]+5:edges[-1]-5]\n",
    "    \n",
    "    # set baseline to average of first and last 10 pixels\n",
    "    baseline = np.mean(np.concatenate((trace[:10], trace[-10:])))\n",
    "    trace -= baseline # subtract baseline\n",
    "    trace[trace < 0] = 0 # set negative values to 0\n",
    "    \n",
    "    return trace\n",
    "def analyze_trace(trace):\n",
    "    tsum1 = np.cumsum(trace)\n",
    "    tsum2 = np.cumsum(trace[::-1])[::-1]\n",
    "    # find edges of trace peak\n",
    "    cutoff=np.mean(trace) \n",
    "    ledge=np.arange(tsum1.shape[0])[tsum1 >= cutoff][0]\n",
    "    redge=np.arange(tsum2.shape[0])[tsum2 >= cutoff][-1]\n",
    "    \n",
    "    trace_width = redge - ledge # width of trace peak\n",
    "    \n",
    "    trace = trace[ledge:redge] # crop trace to edges\n",
    "    \n",
    "    trace_max = np.max(trace) # peak height of trace\n",
    "    trace_avg = np.mean(trace) # average height of trace (ignoring baseline)\n",
    "    \n",
    "    # determine number of peaks in trace\n",
    "    trace_diff = np.diff(trace)\n",
    "    trace_diff = np.convolve(trace_diff, np.ones(5), mode='same') # smooth trace_diff with moving average\n",
    "    trace_diff[trace_diff <= 0] = -1 # set negative values to -1\n",
    "    trace_diff[trace_diff > 0] = 1 # set positive values to 1\n",
    "    trace_diff = -1*np.diff(trace_diff) # separate to only look for changes in slope direction\n",
    "    num_peaks = np.sum(trace_diff > 0) # number of peaks in trace\n",
    "    \n",
    "    return trace_width, trace_max, trace_avg, num_peaks\n",
    "def analyze_track(track):\n",
    "    length = (track.shape[0]**2 + track.shape[1]**2)**0.5 # length of track\n",
    "    num_pads = track[track>0].reshape(-1).shape[0] # pads in track\n",
    "    width = num_pads / length # width of track\n",
    "    \n",
    "    # number of pixels in track larger than all surrounding pixels in 3x3 window\n",
    "    num_peaks = np.sum(track[1:-1,1:-1] > np.max(np.array([track[:-2,:-2], track[:-2,1:-1], track[:-2,2:], track[1:-1,:-2], track[1:-1,2:], track[2:,:-2], track[2:,1:-1], track[2:,2:]]), axis=0))\n",
    "    \n",
    "    num_noise = 0\n",
    "    # look for free-standing pads with no neighbors\n",
    "    track = np.pad(track, ((1,1),(1,1)), mode='constant', constant_values=0) # pad track with 0s\n",
    "    for i in range(1,track.shape[0]-1):\n",
    "        for j in range(1,track.shape[1]-1):\n",
    "            if track[i,j] > 0 and np.sum(track[i-1:i+2,j]) == track[i,j] and np.sum(track[i,j-1:j+2]) == track[i,j]:\n",
    "                # not including diagonal neighbors\n",
    "                num_noise += 1\n",
    "    num_peaks -= num_noise # subtract free-standing pads from num_peaks\n",
    "    \n",
    "    # pad energy statistics\n",
    "    track = track[track > 0] # remove 0s\n",
    "    max_pad = np.max(track) # highest measured pad energy\n",
    "    min_pad = np.min(track) # lowest measured pad energy\n",
    "    avg_pad = np.mean(track) # average pad energy\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return length, width, num_pads, num_peaks, max_pad, min_pad, avg_pad, num_noise\n",
    "def get_event_length(length, trace_width):\n",
    "    # weight of trace in length calculation\n",
    "    # obtained by minimizing the standard deviation of the length calculation for events of the same energy\n",
    "    trace_weight = 0.59176\n",
    "    \n",
    "    scale = 1/2.2 # scale factor for length calculation (pads to mm)\n",
    "    overshoot = 0 # overshoot of length calculation (mm)\n",
    "    \n",
    "    return scale*(length**2 + trace_weight*trace_width**2)**0.5 - overshoot\n",
    "\n",
    "def Analyze_Image(file_dir):\n",
    "    img_array = np.array(Image.open(file_dir))[:,:,:3]\n",
    "    event_energy = get_energy(img_array)\n",
    "    track = get_track(img_array)\n",
    "    trace = get_trace(img_array)\n",
    "\n",
    "    # normalize energy\n",
    "    track = event_energy * track / np.sum(track) # assumes all energy is represented in track pixels, bad with high threshold\n",
    "    trace = event_energy * trace / np.sum(trace)\n",
    "\n",
    "    trace_width, trace_max, trace_avg, trace_peaks = analyze_trace(trace)\n",
    "    track_length, track_width, num_pads, track_peaks, max_pad, min_pad, avg_pad, num_noise = analyze_track(track)\n",
    "\n",
    "    event_length = get_event_length(track_length, trace_width)\n",
    "    num_peaks = np.max((trace_peaks, track_peaks))\n",
    "\n",
    "    attributes = {\n",
    "        'Energy' : event_energy,\n",
    "        'Length' : event_length,\n",
    "        'Width' : track_width,\n",
    "        'NumPads' : num_pads,\n",
    "        'NumPeaks' : num_peaks,\n",
    "        'MaxPad' : max_pad,\n",
    "        'MinPad' : min_pad,\n",
    "        'AvgPad' : avg_pad,\n",
    "        'NumNoise' : num_noise\n",
    "    }\n",
    "    \n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events(event_list):\n",
    "    for event in event_list:\n",
    "        pass \n",
    "    \n",
    "    return event_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iteration == 0: # analyze target images for scoring reference\n",
    "    tuning_dirs = { # directories of tuning images from real data\n",
    "        '806p' : \"/mnt/analysis/e21072/h5test/run_0277/len90_ic600000_pads21_eps5_samps5_poly2/673876CUT_Date_12_20_2023/\",\n",
    "        '1682p' : \"/mnt/analysis/e21072/h5test/run_0277/len90_ic600000_pads21_eps5_samps5_poly2/241372CUT_Date_12_20_2023/\"\n",
    "    }\n",
    "    \n",
    "    tuning_log = json.load(open(automation_dir + 'simInput/tuning_log.json', 'r'))\n",
    "    \n",
    "    # validate that all tuning particles have matches and images exist\n",
    "    for particle in tuning_log['TuningParticles']:\n",
    "        if particle not in tuning_dirs.keys():\n",
    "            raise ValueError(f\"Particle {particle} not found in tuning_dirs\")\n",
    "        if not os.path.isdir(tuning_dirs[particle]):\n",
    "            raise ValueError(f\"Directory {tuning_dirs[particle]} not found\")\n",
    "        if len(os.listdir(tuning_dirs[particle])) == 0:\n",
    "            raise ValueError(f\"No images found in {tuning_dirs[particle]}\")\n",
    "    \n",
    "    tuning_log['TargetAttributes'] = {} # initialize target attributes\n",
    "    \n",
    "    for particle in tuning_log['TuningParticles']:\n",
    "        print(f\"Analyzing target {particle} images\")\n",
    "        tuning_log['TargetAttributes'][particle] = {} # attributes for each particle type\n",
    "        event_list = []\n",
    "        for file in os.listdir(tuning_dirs[particle]):\n",
    "            if file.endswith('.png'):\n",
    "                event_list.append(Analyze_Image(tuning_dirs[particle] + file))\n",
    "        \n",
    "        # filter out events with bad attributes\n",
    "        for event in event_list:\n",
    "            event_list = filter_events(event_list)\n",
    "        \n",
    "        # average attributes of all images\n",
    "        for attribute in event_list[0].keys():\n",
    "            tuning_log['TargetAttributes'][particle][attribute] = np.mean([event_list[i][attribute] for i in range(len(event_list))])\n",
    "        \n",
    "        # save target attributes to json file\n",
    "        with open(automation_dir + 'simInput/tuning_log.json', 'w') as f:\n",
    "            json.dump(tuning_log, f, indent=4)\n",
    "        \n",
    "        # save target attributes to csv file\n",
    "        attribute_df = pd.DataFrame(tuning_log['TargetAttributes']).T\n",
    "        attribute_df.index.name = 'Sim'\n",
    "        attribute_df.to_csv(automation_dir + 'simOutput/AttributesLog.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scoring_Function(attributes, particle, tuning_log):\n",
    "    # calculate score for each attribute\n",
    "    score = 0\n",
    "    for attribute in attributes.keys():\n",
    "        # Square deviation of attribute from target value (lower is better)\n",
    "        score += (attributes[attribute] - tuning_log['TargetAttributes'][particle][attribute])**2\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score_Simulations(param_df=param_df, image_dir = automation_dir+'simOutput/images/', tuning_log=tuning_log, automation_dir=automation_dir):\n",
    "    full_image_list = [i for i in os.listdir(image_dir) if i.endswith('.png')]\n",
    "    \n",
    "    Attribute_df = pd.read_csv(automation_dir + 'simOutput/AttributesLog.csv')\n",
    "    \n",
    "    for index, row in param_df.iterrows():\n",
    "        if row['Score'] == -1: # if the score hasn't been measured yet\n",
    "            sim_name = row['Sim']\n",
    "            sim_image_list = [i for i in full_image_list if i.split('_image_')[0] == sim_name]\n",
    "            \n",
    "            ptype = ''\n",
    "            if row['E0'] > 1:\n",
    "                ptype += f\"{int(row['E0'])}p\"\n",
    "            if row['E1'] > 1:\n",
    "                ptype += f\"{int(row['E1'])}a\"\n",
    "            \n",
    "            sim_events = []\n",
    "            for image in sim_image_list:\n",
    "                sim_events.append(Analyze_Image(image_dir + image))\n",
    "            sim_events = filter_events(sim_events)\n",
    "            \n",
    "            sim_attributes = {}\n",
    "            for attribute in sim_events[0].keys():\n",
    "                sim_attributes[attribute] = np.mean([sim_events[i][attribute] for i in range(len(sim_events))])\n",
    "            \n",
    "            # add row for simulation to attribute log\n",
    "            Attribute_df.loc[len(Attribute_df)] = np.nan # add row to attribute log\n",
    "            Attribute_df.loc[len(Attribute_df)-1, 'Sim'] = sim_name\n",
    "            for attribute in sim_attributes.keys():\n",
    "                Attribute_df.loc[len(Attribute_df)-1, attribute] = sim_attributes[attribute]\n",
    "            \n",
    "            # score the simulation\n",
    "            score = Scoring_Function(sim_attributes, ptype, tuning_log)\n",
    "            \n",
    "            # save score to parameter file\n",
    "            param_df.loc[index, 'Score'] = score\n",
    "        \n",
    "        Attribute_df.to_csv(automation_dir + 'simOutput/AttributesLog.csv', index=False)\n",
    "        \n",
    "    return param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_sim(sim_name, ptype, tuning_log=tuning_log, param_df=param_df):\n",
    "    if sim_name not in param_df['Sim'].values:\n",
    "        E0 = tuning_log['ZeroEnergy']\n",
    "        E1 = tuning_log['ZeroEnergy']\n",
    "        if 'p' in ptype: # proton present\n",
    "            E0 = float(ptype.split('p')[0])\n",
    "        if 'a' in ptype: # alpha present\n",
    "            E1 = float(ptype.split('a')[0].split('p')[-1])\n",
    "            \n",
    "        param_df.loc[len(param_df)] = np.nan # add row to parameter file\n",
    "        \n",
    "        # set parameters to default values\n",
    "        param_df.loc[len(param_df)-1, 'Sim'] = sim_name\n",
    "        param_df.loc[len(param_df)-1, 'Status'] = 0\n",
    "        param_df.loc[len(param_df)-1, 'P0'] = 'p'\n",
    "        param_df.loc[len(param_df)-1, 'E0'] = E0\n",
    "        param_df.loc[len(param_df)-1, 'P1'] = 'a'\n",
    "        param_df.loc[len(param_df)-1, 'E1'] = E1\n",
    "        param_df.loc[len(param_df)-1, 'N'] = tuning_log['N']\n",
    "        param_df.loc[len(param_df)-1, 'Seed'] = tuning_log['Seed']\n",
    "        param_df.loc[len(param_df)-1, 'Score'] = -1\n",
    "        for param in tuning_log['Parameters'].keys():\n",
    "            param_df.loc[len(param_df)-1, param] = tuning_log['Parameters'][param]\n",
    "    else:\n",
    "        print(f\"Simulation {sim_name} already initialized\")\n",
    "    return param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All simulations have been run successfully, so continue with tuning process\n",
    "# Read in the tuning log\n",
    "with open(automation_dir + 'simInput/tuning_log.json', 'r') as f:\n",
    "    tuning_log = json.load(f)\n",
    "\n",
    "# Read in the scores from the previous iterations\n",
    "if iteration > 0:\n",
    "    param_df = Score_Simulations()\n",
    "\n",
    "update_success = False\n",
    "if iteration > 0: # calculate gradient and update parameters\n",
    "    # central value simulation results\n",
    "    center_score = param_df.loc[param_df['Sim'] == f\"T{tuning_log['Batch']}C\", 'Score'].values[0] # score of central value simulation\n",
    "    center_param = param_df.loc[param_df['Sim'] == f\"T{tuning_log['Batch']}C\", tuning_log['VarParam']].values[0] # central value of parameter\n",
    "    \n",
    "    gradient_sims = param_df['Sim'][param_df['Sim'].str.contains(f\"T{tuning_log['Batch']}G\")].values # filter to only gradient simulations from this batch\n",
    "    gradient_iters = [int(sim.split('G')[-1]) for sim in gradient_sims] # iteration number of each gradient simulation\n",
    "    # compare largest iteration number gradient sim to central value sim\n",
    "    \n",
    "    gradient_sim = param_df[param_df['Sim'] == f\"T{tuning_log['Batch']}G{max(gradient_iters)}\"] # largest iteration number gradient sim\n",
    "    gradient_score = gradient_sim['Score'].values[0] # score of largest iteration number gradient sim\n",
    "    gradient_param = gradient_sim[tuning_log['VarParam']].values[0] # parameter value of largest iteration number gradient sim\n",
    "    \n",
    "    # calculate gradient\n",
    "    gradient = (gradient_param - center_param) / (gradient_score - center_score)\n",
    "    \n",
    "    if gradient != 0:\n",
    "        # update parameter value\n",
    "        tuning_log['Gradient'][tuning_log['VarParam']] = gradient\n",
    "        tuning_log['Parameters'][tuning_log['VarParam']] -= tuning_log['LearningRate'] * gradient\n",
    "        param_df.loc[param_df['Sim'].str.contains(f\"T{tuning_log['Batch']}\"), 'Status'] = 5\n",
    "        tuning_log['Batch'] += 1       \n",
    "        update_success = True\n",
    "    elif max(gradient_iters) > 10:\n",
    "        # if gradient is 0, but there are already 10 gradient simulations, assume that the parameter is already at the optimal value\n",
    "        param_df.loc[param_df['Sim'].str.contains(f\"T{tuning_log['Batch']}\"), 'Status'] = 5\n",
    "        tuning_log['Batch'] += 1\n",
    "        update_success = True\n",
    "    else: # take larger step if gradient is 0\n",
    "        gradient_iter = max(gradient_iters) + 1\n",
    "        param_df = initialize_sim(f\"T{tuning_log['Batch']}G{gradient_iter}\", tuning_log['VarPType']) # queue new gradient simulation\n",
    "        param_jump = (gradient_param - center_param) / (gradient_iter) * (gradient_iter+1)\n",
    "        \n",
    "        if tuning_log['VarParam'] in tuning_log['IntParams']: # round to nearest integer if parameter must be integer\n",
    "            param_jump = int(param_jump)\n",
    "            if param_jump == 0:\n",
    "                param_jump = int(float(param_jump)/float(np.abs(param_jump))) # smallest jump is +/- 1 if parameter is integer\n",
    "        param_df.loc[param_df['Sim'] == f\"T{tuning_log['Batch']}G{gradient_iter}\", tuning_log['VarParam']] -= param_jump\n",
    "    \n",
    "    # save updated tuning log\n",
    "    with open(automation_dir + 'simInput/tuning_log.json', 'w') as f:\n",
    "        json.dump(tuning_log, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload tuning log in case it was updated\n",
    "with open(automation_dir + 'simInput/tuning_log.json', 'r') as f:\n",
    "    tuning_log = json.load(f)\n",
    "\n",
    "if update_success or iteration == 0: # queue new simulations\n",
    "    # TODO : weight selection by previously measured gradients and/or amount of times each parameter / particle type has been tested already\n",
    "    tuning_log['VarParam'] = random.choice(list(tuning_log['Parameters'].keys())) # choose a random parameter to change\n",
    "    tuning_log['VarPType'] = random.choice(tuning_log['TuningParticles']) # choose a random particle type to simulate\n",
    "    \n",
    "    param_df = initialize_sim(f\"T{tuning_log['Batch']}C\", tuning_log['VarPType'], param_df=param_df) # central value simulation\n",
    "\n",
    "    # gradient simulation 0\n",
    "    param_jump = tuning_log['LearningRate'] * tuning_log['TestJump'] * tuning_log['Gradient'][tuning_log['VarParam']] # amount to change parameter by for measuring gradient\n",
    "    if tuning_log['VarParam'] in tuning_log['IntParams']: # round to nearest integer if parameter must be integer\n",
    "        if int(param_jump) == 0:\n",
    "            param_jump = int(float(param_jump)/float(np.abs(param_jump))) # ensure that parameter is changed by at least +/- 1 if it is an integer         \n",
    "        else:\n",
    "            param_jump = int(param_jump)\n",
    "    param_df = initialize_sim(f\"T{tuning_log['Batch']}G0\", tuning_log['VarPType'], param_df=param_df)\n",
    "    param_df.loc[param_df['Sim'] == f\"T{tuning_log['Batch']}G0\", tuning_log['VarParam']] -= param_jump\n",
    "\n",
    "\n",
    "# set integer parameters to integers \n",
    "for param in tuning_log['IntParams']:\n",
    "    param_df[param] = param_df[param].astype(int)\n",
    "\n",
    "param_df.to_csv(automation_dir + 'simInput/parameters.csv', index=False)\n",
    "with open(automation_dir + 'simInput/tuning_log.json', 'w') as f:\n",
    "    json.dump(tuning_log, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iteration > 0: # VISUALIZATION OF TUNING PROGRESS\n",
    "    try:\n",
    "        with open (automation_dir + \"simInput/tuning_log.json\", \"r\") as f:\n",
    "            tuning_log = json.load(f)\n",
    "\n",
    "        param_df = pd.read_csv(automation_dir + \"simInput/parameters.csv\")\n",
    "        attributes_df = pd.read_csv(automation_dir + \"simOutput/AttributesLog.csv\")\n",
    "\n",
    "        param_df = param_df[param_df['Score'] >= 0] # filter out simulations that have not been scored yet\n",
    "\n",
    "        ptypes = attributes_df['Sim'].values.tolist()\n",
    "        ptypes = [x for x in ptypes if 'T' not in x] # remove tuning simulations for only real particles\n",
    "        \n",
    "        def str_to_float(str, tuning_log=tuning_log):\n",
    "            if str != '':\n",
    "                return float(str)\n",
    "            else:\n",
    "                return float(tuning_log['ZeroEnergy'])\n",
    "\n",
    "        attr = attributes_df.columns.values.tolist()\n",
    "        attr = [x for x in attr if x not in ['Sim', 'Energy']]\n",
    "\n",
    "        fig, axes = plt.subplots(len(attr), len(ptypes), figsize=(12, 6))\n",
    "        for i, particle in enumerate(ptypes):\n",
    "            E0 = str_to_float(particle.split('a')[0].split('p')[0])\n",
    "            E1 = str_to_float(particle.split('a')[0].split('p')[1])\n",
    "            \n",
    "            ptype_sims_params = param_df[param_df['E0'] == E0]\n",
    "            ptype_sims_params = ptype_sims_params[ptype_sims_params['E1'] == E1]\n",
    "            \n",
    "            ptype_sims = ptype_sims_params['Sim'].values.tolist()\n",
    "            \n",
    "            ptype_attr = attributes_df[attributes_df['Sim'].isin(ptype_sims)]\n",
    "            \n",
    "            axes[0, i].set_title(particle)\n",
    "            for j, atr in enumerate(attr):\n",
    "                axes[j, i].plot(ptype_attr.index, ptype_attr[atr], 'o')\n",
    "                axes[j, 0].set_ylabel(atr)\n",
    "                \n",
    "                # horizontal line for tuning value\n",
    "                axes[j,i].axhline(y=tuning_log['TargetAttributes'][particle][atr], color='k', linestyle='--')\n",
    "                \n",
    "        plt.savefig(automation_dir + \"simOutput/Attributes.png\")\n",
    "\n",
    "        param_cols = param_df.columns.values.tolist()\n",
    "        param_cols = [x for x in param_cols if x not in ['Sim', 'E0', 'E1', 'Status', 'P0', 'P1', 'N', 'Seed', 'Batch']]\n",
    "\n",
    "        param_df['Batch'] = param_df['Sim'].apply(lambda x: float(x.split('T')[1].split('C')[0].split('G')[0]))\n",
    "        center_params = param_df[param_df['Sim'].str.contains('C')]\n",
    "\n",
    "        fig, axes = plt.subplots(len(param_cols), 1, figsize=(12, 6))\n",
    "        for i, param in enumerate(param_cols):\n",
    "            axes[i].plot(center_params['Batch'], center_params[param], color='r')\n",
    "            axes[i].plot(param_df['Batch'], param_df[param], 'o', markersize=1, color='k')\n",
    "            axes[i].set_ylabel(param)\n",
    "\n",
    "        plt.savefig(automation_dir + \"simOutput/Parameters.png\")\n",
    "    except:\n",
    "        sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
