{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from pca import pca\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "import peakutils\n",
    "import os, sys\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "from sklearn.cluster import DBSCAN\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "\tdef __enter__(self):\n",
    "\t\tself._original_stdout = sys.stdout\n",
    "\t\tsys.stdout = open(os.devnull, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "\tsys.stdout.close()\n",
    "\tsys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(xset, yset, zset, eset, threshold):\n",
    "\t\"\"\"\n",
    "\tUses DBSCAN to find and remove outliers in 3D data\n",
    "\t\"\"\"\n",
    "\tdata = np.array([xset.T, yset.T, zset.T]).T\n",
    "\tDBSCAN_cluster = DBSCAN(eps=7, min_samples=10).fit(data)\n",
    "\tout_of_cluster_index = np.where(DBSCAN_cluster.labels_==-1)\n",
    "\tdel data\n",
    "\trev = out_of_cluster_index[0][::-1]\n",
    "\t#if len(out_of_cluster_index[0]) > 0:\n",
    "\tfor i in rev:\n",
    "\t\txset = np.delete(xset, i)\n",
    "\t\tyset = np.delete(yset, i)\n",
    "\t\tzset = np.delete(zset, i)\n",
    "\t\teset = np.delete(eset, i)\n",
    "\t#if len(xset) <= threshold:\n",
    "\t#\tveto = True\n",
    "\t#else:\n",
    "    #veto = False\n",
    "\treturn xset, yset, zset, eset, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veto on Length @ 70 mm\n",
      "Veto on Integrated Charge @ 800k\n"
     ]
    }
   ],
   "source": [
    "print('Veto on Length @ 70 mm')\n",
    "print('Veto on Integrated Charge @ 800k')\n",
    "def track_len(xset, yset, zset):\n",
    "    \"\"\"\n",
    "    Uses PCA to find the length of a track\n",
    "    \"\"\"\n",
    "    veto_on_length = False\n",
    " \n",
    "    # Form data matrix\n",
    "    data = np.concatenate((xset[:, np.newaxis], \n",
    "                           yset[:, np.newaxis], \n",
    "                           zset[:, np.newaxis]), \n",
    "                           axis=1)\n",
    "\n",
    "    # Use PCA to find track length\n",
    "    pca = PCA(n_components=3)\n",
    "    principalComponents = pca.fit(data)\n",
    "    principalComponents = pca.transform(data)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "    \n",
    "    track_len = 2.35*principalDf.std()[0]\n",
    "    track_width = 2.35*principalDf.std()[1]\n",
    "    track_depth = 2.35*principalDf.std()[2]\n",
    "    #if track_len > 70:\n",
    "    #    veto_on_length = True\n",
    "    \n",
    "    return track_len, veto_on_length, track_width, track_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(h5file, threshold):\n",
    "    \"\"\"\n",
    "    This functions does the following: \n",
    "    - Converts h5 files into ndarrays. \n",
    "    - Removes outliers.\n",
    "    - Calls PCA to return track length.\n",
    "    - Sums mesh signal to return energy.\n",
    "    \"\"\"\n",
    "    # Converts h5 files into ndarrays, and output each event dataset as a separte list\n",
    "    num_events = int(len(list(h5file.keys()))/2) \n",
    "    \n",
    "    len_list = []\n",
    "    width_list = []\n",
    "    depth_list = []\n",
    "    good_events = []\n",
    "    tot_energy = []\n",
    "    tracemax_list = []\n",
    "    tracedev_list = []\n",
    "    pads_list = []\n",
    "    \n",
    "    skipped_events = 0\n",
    "    veto_events = 0\n",
    "    \n",
    "    pbar = tqdm(total=num_events+1)\n",
    "    for i in range(0, num_events):\n",
    "        str_event = f\"Event_[{i}]\"\n",
    "        \n",
    "        # Apply pad threshold\n",
    "        event = np.array(h5file[str_event][:])\n",
    "        if len(event) <= threshold:\n",
    "            skipped_events += 1\n",
    "            pbar.update(n=1)\n",
    "            continue\n",
    "            \n",
    "        # Make copy of datasets\n",
    "        dset_0_copyx = event['x']\n",
    "        dset_0_copyy = event['y'] \n",
    "        dset_0_copyz = event['z'] - min(event['z'])\n",
    "        dset_0_copye = event['A']\n",
    "\n",
    "        \n",
    "        # Apply veto condition\n",
    "        R = 36                           # Radius of the pad plane\n",
    "        r = np.sqrt(dset_0_copyx**2 + dset_0_copyy**2)\n",
    "        statements = np.greater(r, R)    # Check if any point lies outside of R\n",
    "      \n",
    "        if np.any(statements) == True:\n",
    "            veto_events += 1\n",
    "            pbar.update(n=1)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Call remove_outliers to get dataset w/ outliers removed\n",
    "        dset_0_copyx, dset_0_copyy, dset_0_copyz, dset_0_copye, veto = remove_outliers(dset_0_copyx, dset_0_copyy, dset_0_copyz, dset_0_copye, threshold)\n",
    "        if veto == True:\n",
    "            skipped_events += 1\n",
    "            pbar.update(n=1)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Call track_len() to create lists of all track lengths\n",
    "        length, veto_on_length, width, depth = track_len(dset_0_copyx, dset_0_copyy, dset_0_copyz)\n",
    "        if veto_on_length == True:\n",
    "            veto_events += 1\n",
    "            pbar.update(n=1)\n",
    "            continue\n",
    "\n",
    "        \n",
    "       \tstr_trace = f\"Trace_[{i}]\"\n",
    "        trace = np.array(h5file[str_trace][:])\n",
    "        max_val = np.argmax(trace)\n",
    "        low_bound = max_val - 75\n",
    "        if low_bound < 0:\n",
    "            low_bound = 5\n",
    "        upper_bound = max_val + 75\n",
    "        if upper_bound > 511:\n",
    "            upper_bound = 506\n",
    "        trace = trace[low_bound:upper_bound]\n",
    "\n",
    "        polynomial_degree=2 \n",
    "        baseObj=BaselineRemoval(trace)\n",
    "        trace=baseObj.IModPoly(polynomial_degree)\n",
    "\n",
    "        #if np.sum(trace) > 800000:\n",
    "        #    veto_events += 1\n",
    "        #    pbar.update(n=1)\n",
    "        #    continue\n",
    "\n",
    "        len_list.append(length)\n",
    "        width_list.append(width)\n",
    "        depth_list.append(depth)\n",
    "        tot_energy.append(np.sum(trace))\n",
    "        tracemax_list.append(np.max(trace))\n",
    "        tracedev_list.append(np.std(trace))\n",
    "        pads_list.append(len(trace[trace > 0]))\n",
    "\n",
    "        # Track event number of good events\n",
    "        good_events.append(i)  \n",
    "        pbar.update(n=1)\n",
    "\n",
    "    return (tot_energy, skipped_events, veto_events, good_events, len_list, width_list, depth_list, tracemax_list, tracedev_list, pads_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Adam/OneDrive - Tenundra, Inc/Shared with Everyone/simOutput/1200p.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [00:05<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Adam/OneDrive - Tenundra, Inc/Shared with Everyone/simOutput/1200p500a.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [00:04<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Adam/OneDrive - Tenundra, Inc/Shared with Everyone/simOutput/500a.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [00:00<00:00, 1110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Adam/OneDrive - Tenundra, Inc/Shared with Everyone/simOutput/800p.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [00:04<00:00, 22.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# assign directory\n",
    "directory = \"C:/Users/Adam/OneDrive - Tenundra, Inc/Shared with Everyone/simOutput/\"\n",
    "\n",
    "output_df = pd.DataFrame(columns=['file','event','length', 'width', 'depth', 'tracesum', 'tracemax', 'tracedev', 'padnum'])\n",
    "\n",
    "file_names = []\n",
    "# iterate over files in directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        if f[-3:] == '.h5':\n",
    "            print(f)\n",
    "            file_names.append(filename)\n",
    "            h5f = h5py.File(directory+filename, 'r')\n",
    "            (tot_energy, skipped_events, veto_events, good_events, len_list, width_list, depth_list, tracemax_list, tracedev_list, pads_list) = main(h5file=h5f, threshold=15)\n",
    "            for event in range(len(tot_energy)):\n",
    "                output_df = output_df.append({'file' : filename, \n",
    "                                              'event' : event, \n",
    "                                              'length' : len_list[event], \n",
    "                                              'width' : width_list[event], \n",
    "                                              'depth' : depth_list[event], \n",
    "                                              'tracesum' : tot_energy[event], \n",
    "                                              'tracemax' : tracemax_list[event], \n",
    "                                              'tracedev' : tracedev_list[event], \n",
    "                                              'padnum' : pads_list[event]}\n",
    "                                             ,ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200p.h5\n",
      "length:\t 23.624050598593197 \t 0.8731217694070188\n",
      "width:\t 6.14313217499254 \t 0.22495854146050637\n",
      "depth:\t 3.5936199364238144 \t 0.7615437968948063\n",
      "tracesum:\t 129984.16419265946 \t 343.9733728278827\n",
      "tracemax:\t 9098.907010970106 \t 756.6866462906265\n",
      "tracedev:\t 2204.6879055772197 \t 103.03661220901206\n",
      "padnum:\t 84.51162790697674 \t 1.8305878970228298\n",
      "\n",
      "1200p500a.h5\n",
      "length:\t 23.624050598593197 \t 0.8731217694070188\n",
      "width:\t 6.14313217499254 \t 0.22495854146050637\n",
      "depth:\t 3.5936199364238144 \t 0.7615437968948063\n",
      "tracesum:\t 129984.16419265946 \t 343.9733728278827\n",
      "tracemax:\t 9098.907010970106 \t 756.6866462906265\n",
      "tracedev:\t 2204.6879055772197 \t 103.03661220901206\n",
      "padnum:\t 84.51162790697674 \t 1.8305878970228298\n",
      "\n",
      "500a.h5\n",
      "length:\t nan \t nan\n",
      "width:\t nan \t nan\n",
      "depth:\t nan \t nan\n",
      "tracesum:\t nan \t nan\n",
      "tracemax:\t nan \t nan\n",
      "tracedev:\t nan \t nan\n",
      "padnum:\t nan \t nan\n",
      "\n",
      "800p.h5\n",
      "length:\t 14.005620449111305 \t 1.0727717058353359\n",
      "width:\t 6.235889868567331 \t 0.2504531717573014\n",
      "depth:\t 3.568149356077781 \t 0.654112692793054\n",
      "tracesum:\t 86636.90407692472 \t 358.09372995852965\n",
      "tracemax:\t 6433.046424362378 \t 166.91668707264114\n",
      "tracedev:\t 1519.2018797408277 \t 22.721431965189186\n",
      "padnum:\t 85.32558139534883 \t 1.554117882281321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    print(file)\n",
    "    print('length:\\t', output_df[output_df['file'] == file]['length'].mean(),'\\t', output_df[output_df['file'] == file]['length'].std())\n",
    "    print('width:\\t', output_df[output_df['file'] == file]['width'].mean(),'\\t', output_df[output_df['file'] == file]['width'].std())\n",
    "    print('depth:\\t', output_df[output_df['file'] == file]['depth'].mean(),'\\t', output_df[output_df['file'] == file]['depth'].std())\n",
    "    print('tracesum:\\t', output_df[output_df['file'] == file]['tracesum'].mean(),'\\t', output_df[output_df['file'] == file]['tracesum'].std())\n",
    "    print('tracemax:\\t', output_df[output_df['file'] == file]['tracemax'].mean(),'\\t', output_df[output_df['file'] == file]['tracemax'].std())\n",
    "    print('tracedev:\\t', output_df[output_df['file'] == file]['tracedev'].mean(),'\\t', output_df[output_df['file'] == file]['tracedev'].std())\n",
    "    print('padnum:\\t', output_df[output_df['file'] == file]['padnum'].mean(),'\\t', output_df[output_df['file'] == file]['padnum'].std())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('particle_types_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>event</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "      <th>tracesum</th>\n",
       "      <th>tracemax</th>\n",
       "      <th>tracedev</th>\n",
       "      <th>padnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200p.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>21.131043</td>\n",
       "      <td>6.571122</td>\n",
       "      <td>3.716608</td>\n",
       "      <td>129903.950146</td>\n",
       "      <td>7723.651277</td>\n",
       "      <td>2012.537171</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200p.h5</td>\n",
       "      <td>1</td>\n",
       "      <td>24.287763</td>\n",
       "      <td>6.418697</td>\n",
       "      <td>2.281732</td>\n",
       "      <td>129446.9175</td>\n",
       "      <td>7880.465199</td>\n",
       "      <td>2034.222038</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200p.h5</td>\n",
       "      <td>2</td>\n",
       "      <td>25.553696</td>\n",
       "      <td>5.817853</td>\n",
       "      <td>2.794285</td>\n",
       "      <td>130443.794868</td>\n",
       "      <td>7820.231764</td>\n",
       "      <td>2031.53888</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200p.h5</td>\n",
       "      <td>3</td>\n",
       "      <td>23.02706</td>\n",
       "      <td>6.337398</td>\n",
       "      <td>4.081462</td>\n",
       "      <td>129866.406753</td>\n",
       "      <td>9400.732296</td>\n",
       "      <td>2243.879999</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200p.h5</td>\n",
       "      <td>4</td>\n",
       "      <td>23.002763</td>\n",
       "      <td>6.236723</td>\n",
       "      <td>3.74583</td>\n",
       "      <td>130047.306896</td>\n",
       "      <td>9902.219118</td>\n",
       "      <td>2312.636875</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>800p.h5</td>\n",
       "      <td>38</td>\n",
       "      <td>14.011863</td>\n",
       "      <td>6.114445</td>\n",
       "      <td>3.807303</td>\n",
       "      <td>86911.349693</td>\n",
       "      <td>6645.529466</td>\n",
       "      <td>1549.836952</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>800p.h5</td>\n",
       "      <td>39</td>\n",
       "      <td>14.218191</td>\n",
       "      <td>5.927384</td>\n",
       "      <td>2.895661</td>\n",
       "      <td>86278.735118</td>\n",
       "      <td>6481.648573</td>\n",
       "      <td>1529.739959</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>800p.h5</td>\n",
       "      <td>40</td>\n",
       "      <td>14.150972</td>\n",
       "      <td>6.088355</td>\n",
       "      <td>4.477363</td>\n",
       "      <td>86171.521129</td>\n",
       "      <td>6518.706225</td>\n",
       "      <td>1528.759662</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>800p.h5</td>\n",
       "      <td>41</td>\n",
       "      <td>10.184042</td>\n",
       "      <td>6.405383</td>\n",
       "      <td>2.256857</td>\n",
       "      <td>86893.063655</td>\n",
       "      <td>6092.261564</td>\n",
       "      <td>1475.708471</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>800p.h5</td>\n",
       "      <td>42</td>\n",
       "      <td>13.727038</td>\n",
       "      <td>6.228185</td>\n",
       "      <td>4.303005</td>\n",
       "      <td>86879.388689</td>\n",
       "      <td>6612.649062</td>\n",
       "      <td>1546.542877</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file event     length     width     depth       tracesum  \\\n",
       "0    1200p.h5     0  21.131043  6.571122  3.716608  129903.950146   \n",
       "1    1200p.h5     1  24.287763  6.418697  2.281732    129446.9175   \n",
       "2    1200p.h5     2  25.553696  5.817853  2.794285  130443.794868   \n",
       "3    1200p.h5     3   23.02706  6.337398  4.081462  129866.406753   \n",
       "4    1200p.h5     4  23.002763  6.236723   3.74583  130047.306896   \n",
       "..        ...   ...        ...       ...       ...            ...   \n",
       "124   800p.h5    38  14.011863  6.114445  3.807303   86911.349693   \n",
       "125   800p.h5    39  14.218191  5.927384  2.895661   86278.735118   \n",
       "126   800p.h5    40  14.150972  6.088355  4.477363   86171.521129   \n",
       "127   800p.h5    41  10.184042  6.405383  2.256857   86893.063655   \n",
       "128   800p.h5    42  13.727038  6.228185  4.303005   86879.388689   \n",
       "\n",
       "        tracemax     tracedev padnum  \n",
       "0    7723.651277  2012.537171     86  \n",
       "1    7880.465199  2034.222038     84  \n",
       "2    7820.231764   2031.53888     84  \n",
       "3    9400.732296  2243.879999     84  \n",
       "4    9902.219118  2312.636875     88  \n",
       "..           ...          ...    ...  \n",
       "124  6645.529466  1549.836952     85  \n",
       "125  6481.648573  1529.739959     87  \n",
       "126  6518.706225  1528.759662     86  \n",
       "127  6092.261564  1475.708471     82  \n",
       "128  6612.649062  1546.542877     87  \n",
       "\n",
       "[129 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c295b91a4a4f8e66f37da6a2fbf5c84e6919990d10548059361442497be2c972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
