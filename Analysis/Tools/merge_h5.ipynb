{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hdf5_output_directory = \"/mnt/analysis/e17023/Adam/GAPA/Output/hdf5/\"\n",
    "merged_simulation_file = \"simulations_merged.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_h5_list = [filename for filename in os.listdir(Hdf5_output_directory) if filename.endswith('.h5')]\n",
    "if len(component_h5_list) == 0:\n",
    "    raise FileNotFoundError(\"No .h5 files found in the specified directory.\")\n",
    "if merged_simulation_file in component_h5_list:\n",
    "    print(f\"Warning: {merged_simulation_file} already exists in the directory. It will be overwritten.\")\n",
    "    os.remove(f\"{Hdf5_output_directory}{merged_simulation_file}\")\n",
    "    component_h5_list.remove(merged_simulation_file)\n",
    "component_h5_list.sort()\n",
    "\n",
    "# copy first file as template\n",
    "template_h5 = component_h5_list.pop(0)\n",
    "os.system(f\"cp {Hdf5_output_directory}{template_h5} {Hdf5_output_directory}{merged_simulation_file}\")\n",
    "\n",
    "for component_h5 in component_h5_list:\n",
    "    batch_h5 = h5py.File(f\"{Hdf5_output_directory}{merged_simulation_file}\", 'a')\n",
    "    component_h5 = h5py.File(f\"{Hdf5_output_directory}{component_h5}\", 'r')\n",
    "    \n",
    "    # get the event number of the last event in the batch\n",
    "    last_event_number = int(batch_h5['meta/meta'][2]) + 1\n",
    "    \n",
    "    # merge get data\n",
    "    for key in component_h5['get'].keys():\n",
    "        if 'data' in key:\n",
    "            try:\n",
    "                event_number = int(key.split('_')[0][3:])\n",
    "                batch_h5.create_dataset(f\"get/evt{event_number + last_event_number}_header\", data=component_h5[f\"get/{key}\"], dtype='float64')\n",
    "                batch_h5.create_dataset(f\"get/evt{event_number + last_event_number}_data\", data=component_h5[f\"get/{key}\"], dtype='int16')\n",
    "                batch_h5[f'get/evt{event_number + last_event_number}_header'][0] = event_number + last_event_number # update the event number in the header\n",
    "            except IndexError:\n",
    "                print(f\"Error in {component_h5} - {key}\")\n",
    "    meta_data = batch_h5['meta/meta'] \n",
    "    \n",
    "    # merge clouds data\n",
    "    for key in component_h5['clouds'].keys():\n",
    "        event_number = int(key.split('_')[0].split('t')[1]) # evt#_cloud\n",
    "        batch_h5.create_dataset(f\"clouds/evt{event_number + last_event_number}_cloud\", data=component_h5[f\"clouds/{key}\"], dtype='float64')\n",
    "        meta_data[2] = max(meta_data[2], event_number + last_event_number)\n",
    "    \n",
    "    # re-write the meta data\n",
    "    batch_h5['meta'].pop('meta')\n",
    "    batch_h5.create_dataset('meta/meta', data=meta_data, dtype='float64')\n",
    "    \n",
    "    # close the files\n",
    "    component_h5.close()\n",
    "    batch_h5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
